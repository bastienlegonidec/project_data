{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:690: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 5, does not match size of target_names, 4. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 81\u001b[0m\n\u001b[0;32m     78\u001b[0m target_names \u001b[39m=\u001b[39m y_labels[unique_labels_in_predictions]\n\u001b[0;32m     80\u001b[0m \u001b[39m# Évaluation de la performance\u001b[39;00m\n\u001b[1;32m---> 81\u001b[0m classification_rep \u001b[39m=\u001b[39m classification_report(y_test, final_test_pred, target_names\u001b[39m=\u001b[39;49mtarget_names)\n\u001b[0;32m     82\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mClassification Report:\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     83\u001b[0m \u001b[39mprint\u001b[39m(classification_rep)\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\utils\\_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    208\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m    209\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m    211\u001b[0m         )\n\u001b[0;32m    212\u001b[0m     ):\n\u001b[1;32m--> 213\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    214\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    215\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[0;32m    216\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[0;32m    217\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[0;32m    218\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[0;32m    219\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[0;32m    220\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    221\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[0;32m    223\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\leona\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\sklearn\\metrics\\_classification.py:2634\u001b[0m, in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[0;32m   2628\u001b[0m         warnings\u001b[39m.\u001b[39mwarn(\n\u001b[0;32m   2629\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mlabels size, \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m, does not match size of target_names, \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   2630\u001b[0m                 \u001b[39mlen\u001b[39m(labels), \u001b[39mlen\u001b[39m(target_names)\n\u001b[0;32m   2631\u001b[0m             )\n\u001b[0;32m   2632\u001b[0m         )\n\u001b[0;32m   2633\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m-> 2634\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   2635\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mNumber of classes, \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m, does not match size of \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2636\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtarget_names, \u001b[39m\u001b[39m{1}\u001b[39;00m\u001b[39m. Try specifying the labels \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   2637\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mparameter\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mlen\u001b[39m(labels), \u001b[39mlen\u001b[39m(target_names))\n\u001b[0;32m   2638\u001b[0m         )\n\u001b[0;32m   2639\u001b[0m \u001b[39mif\u001b[39;00m target_names \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2640\u001b[0m     target_names \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m l \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m labels]\n",
      "\u001b[1;31mValueError\u001b[0m: Number of classes, 5, does not match size of target_names, 4. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Charger les données\n",
    "df = pd.read_csv(\"dataVisualization/result.csv\")\n",
    "\n",
    "# Supprimer les valeurs manquantes\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Supprimer les valeurs 'Bee & Bumblebee'\n",
    "df = df[df['bug type'] != 'Bee & Bumblebee']\n",
    "\n",
    "# Sélectionner les colonnes de caractéristiques et la cible\n",
    "train_predictor_columns = df.columns.difference(['bug type', 'species'])\n",
    "target_labels = df['bug type']\n",
    "train_feats = df[train_predictor_columns]\n",
    "\n",
    "# Encodage des étiquettes de la cible\n",
    "y_encoded, y_labels = pd.factorize(target_labels)\n",
    "\n",
    "# Division des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(train_feats, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Définir les meilleurs paramètres trouvés pour MLP\n",
    "mlp_params = {\n",
    "    'hidden_layer_sizes': (32, 16, 8),\n",
    "    'alpha': 0.001,\n",
    "    'max_iter': 2000\n",
    "}\n",
    "\n",
    "# Instancier et entraîner le modèle MLP\n",
    "mlp = MLPClassifier(solver='adam', random_state=0, tol=1e-9, **mlp_params)\n",
    "mlp.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédictions MLP\n",
    "mlp_train_pred = mlp.predict(X_train_scaled)\n",
    "mlp_test_pred = mlp.predict(X_test_scaled)\n",
    "\n",
    "# Appliquer SVM avec les meilleurs paramètres trouvés\n",
    "svm_params = {\n",
    "    'C': 100,\n",
    "    'kernel': 'linear',\n",
    "    'degree': 3,\n",
    "    'gamma': 'scale',\n",
    "    'coef0': 0\n",
    "}\n",
    "svm = SVC(**svm_params)\n",
    "svm.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédictions SVM\n",
    "svm_train_pred = svm.predict(X_train_scaled)\n",
    "svm_test_pred = svm.predict(X_test_scaled)\n",
    "\n",
    "# Création de l'ensemble d'entraînement pour le modèle de méta-apprentissage\n",
    "stacked_train_features = np.column_stack((mlp_train_pred, svm_train_pred))\n",
    "stacked_test_features = np.column_stack((mlp_test_pred, svm_test_pred))\n",
    "\n",
    "# Modèle de méta-apprentissage (par exemple, régression logistique)\n",
    "meta_model = LogisticRegression(random_state=0)\n",
    "meta_model.fit(stacked_train_features, y_train)\n",
    "\n",
    "# Prédictions finales\n",
    "final_test_pred = meta_model.predict(stacked_test_features)\n",
    "\n",
    "# Obtenir les étiquettes uniques présentes dans les prédictions finales\n",
    "unique_labels_in_predictions = np.unique(final_test_pred)\n",
    "target_names = y_labels[unique_labels_in_predictions]\n",
    "\n",
    "# Évaluation de la performance\n",
    "classification_rep = classification_report(y_test, final_test_pred, target_names=target_names)\n",
    "print(\"Classification Report:\")\n",
    "print(classification_rep)\n",
    "\n",
    "# Isoler les lignes de result.csv qui ont été utilisées pour tester le modèle\n",
    "test_df = df.loc[X_test.index]\n",
    "test_df.drop(train_predictor_columns, axis=1, inplace=True)\n",
    "test_df.drop(['species'], axis=1, inplace=True)\n",
    "\n",
    "# Création du DataFrame avec les meilleurs résultats\n",
    "results_df = pd.DataFrame({\n",
    "    'bug type': y_labels[y_test],\n",
    "    'Predicted_Bug_Type': y_labels[final_test_pred],\n",
    "    'Recognition': pd.Series(y_labels[y_test]) == pd.Series(y_labels[final_test_pred])\n",
    "})\n",
    "\n",
    "# Convertir les booléens en chaînes \"True\" ou \"False\"\n",
    "test_df['Stacked_Recognition'] = results_df['Recognition'].map({True: 'True', False: 'False'})\n",
    "test_df.to_csv(\"stacked_recognition.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "83db9ccd60aaba7f36d82c7c8a804da99e0bc213c9e856efe6e157fa32ac376b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
